{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration & preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import (make_scorer, mean_squared_error, r2_score,\n",
    "                             root_mean_squared_error)\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/used_cars_UK.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display basic info (num of entries, columns etc.) about dataframe \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(\n",
    "    columns={\n",
    "        \"Price\": \"price\",\n",
    "        \"Mileage(miles)\": \"mileage\",\n",
    "        \"Registration_Year\": \"registration_year\",\n",
    "        \"Previous Owners\": \"previous_owners\",\n",
    "        \"Fuel type\": \"fuel_type\",\n",
    "        \"Body type\": \"body_type\",\n",
    "        \"Engine\": \"engine\",\n",
    "        \"Gearbox\": \"gearbox\",\n",
    "        \"Doors\": \"doors\",\n",
    "        \"Seats\": \"seats\",\n",
    "        \"Emission Class\": \"emission_class\",\n",
    "        \"Service history\": \"service_history\",\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 0\", \"title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display names of the columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    "print(f\"{len(duplicates)} out of {len(df)} rows are duplicated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique values for nominal/categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dtype in zip(df.dtypes.index, df.dtypes.values):\n",
    "    if dtype == \"object\":\n",
    "        print(i, df[i].unique())\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['engine'] = df['engine'].str.replace('L', '', regex=False).astype(float)\n",
    "df['engine'].fillna(df.engine.mean(), inplace=True)\n",
    "df['emission_class'] = df['emission_class'].fillna('Unknown')\n",
    "df['service_history'] = df['service_history'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interval/ratio variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\n",
    "    {\n",
    "        \"mileage\": df[\"mileage\"].median(),\n",
    "        \"registration_year\": df[\"registration_year\"].median(),\n",
    "        \"previous_owners\": df[\"previous_owners\"].median(),\n",
    "        \"engine\": df[\"engine\"].median(),\n",
    "        \"doors\": df[\"doors\"].median(),\n",
    "        \"seats\": df[\"seats\"].median(),\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding for categorical/nominal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Categorical values:\", df.select_dtypes(include='object').columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, ['fuel_type', 'body_type', 'gearbox', 'emission_class', 'service_history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale (numerical) data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_columns = df.select_dtypes(include='number').columns\n",
    "categorical_columns = [col for col in df.columns if col not in numerical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical data\n",
    "scaler = MinMaxScaler()\n",
    "scaled_numerical_data = scaler.fit_transform(df[numerical_columns])\n",
    "scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine scaled numerical data with one-hot encoded categorical data\n",
    "processed_df = pd.concat([scaled_numerical_df, df[categorical_columns].reset_index(drop=True)], axis=1)\n",
    "processed_df_np = processed_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into train & test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    processed_df.drop('price', axis=1).values,\n",
    "    df['price'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 2, 3, 4, 5, 10, 100],  # Range of alpha values\n",
    "    'max_iter': [1000, 5000, 10000],          # Maximum number of iterations\n",
    "    'tol': [1e-4, 1e-3, 1e-2]                # Tolerance for optimization\n",
    "}\n",
    "\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Perform Grid Search\n",
    "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring=scorer, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate R2-score\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "rmse = root_mean_squared_error(y_test, y_test_pred)\n",
    "r2 = r2_score(y_test, y_test_pred)\n",
    "print(\"RMSE:\", round(rmse, 2))\n",
    "print(\"R-squared (R2):\", round(r2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "errors = np.abs(y_test - y_test_pred)  # Absolute errors\n",
    "\n",
    "# Scatter plot with color-coded errors\n",
    "scatter = plt.scatter(y_test, y_test_pred, c=errors, cmap='coolwarm', alpha=0.7, edgecolors='k')\n",
    "plt.colorbar(scatter, label='Prediction Error')\n",
    "\n",
    "# Ideal diagonal line\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], 'r--', lw=2, label='Ideal Fit')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predicted Values (y_test_pred)\")\n",
    "plt.title(\"True vs Predicted Values\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_github",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
